#!/bin/bash
set -e
PREFIX="[dataclaysrv]"
function dataclayecho(){ echo "$PREFIX ${1}"; }
function dataclayerr(){ echo "!! $PREFIX ERROR: ${1}"; exit 1; }
function dataclaywarn(){ echo "$PREFIX WARNING: ${1}"; }
function dataclayinfo(){ echo "$PREFIX ${1}"; }

#=== FUNCTION ================================================================
# NAME: usage
# DESCRIPTION: Display usage information for this script.
# PARAMETER 1: ---
#=============================================================================
function create_globaljob_config {
	mkdir -p $DATACLAY_JOB_FOLDER
	mkdir -p $LOG_DIR
	# Global job config
	echo "######## Global environment variables ########" > $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_VERSION=$DATACLAY_VERSION" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_JOBID=$DATACLAY_JOBID" >> $GLOBAL_JOB_CONFIG
	echo "export LMNODE=$LMNODE" >> $GLOBAL_JOB_CONFIG
	echo "export CLIENTNODE=$CLIENTNODE" >> $GLOBAL_JOB_CONFIG
	echo "export DSNODES=\"$DSNODES\"" >> $GLOBAL_JOB_CONFIG
	echo "export PYTHON_EE_PER_SL=$PYTHON_EE_PER_SL" >> $GLOBAL_JOB_CONFIG
	echo "export JAVA_SL_PER_NODE=$JAVA_SL_PER_NODE" >> $GLOBAL_JOB_CONFIG	
	echo "export PROLOG_SCRIPT=$PROLOG_SCRIPT" >> $GLOBAL_JOB_CONFIG
	echo "export PROLOG_CMD=\"$PROLOG_CMD\"" >> $GLOBAL_JOB_CONFIG
	echo "export DEBUG=$DEBUG" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_USR=$DATACLAY_USR" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_PWD=$DATACLAY_PWD" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_DATASET=$DATACLAY_DATASET" >> $GLOBAL_JOB_CONFIG
	
	echo "export DATACLAY_JAVA_VERSION=$DATACLAY_JAVA_VERSION" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_PYTHON_VERSION=$DATACLAY_PYTHON_VERSION" >> $GLOBAL_JOB_CONFIG
	
	
}

function create_service_config {
	# FIXME: SERVICENAME is a pseudo-global unsafe variable
	# The caller should provide both the JAVA_PORT and PYTHON_PORT
	JAVA_PORT=$1
	PYTHON_PORT=$2
	# Both are required for Python dataservices (as the JAVA_PORT is the StorageLocation,
	# i.e. the Java backend to which Python will connect).
	# Java dataservices only require the JAVA_PORT

	SERVICE_CONFIG=$DATACLAY_JOB_FOLDER/${SERVICENAME}.config
	# Do not use DATACLAY_JOB_FOLDER since it is expanding current $HOME and not remote one
	if [ $SHARED_FS == true ]; then
		SERVICE_FOLDER=$HOME/.dataClay/$DATACLAY_JOBID/${SERVICENAME}
	else
		SERVICE_FOLDER="\$HOME/.dataClay/$DATACLAY_JOBID/${SERVICENAME}"
	fi
	if [ $LMNODE == "localhost" ] || [ $LMNODE == "127.0.0.1" ]; then 
		LOGICMODULE_IP=127.0.0.1
	else 
		LOGICMODULE_IP=`host ${LMNODE} | rev | cut -d ' ' -f1 | rev`
	fi
	#CLIENT_IP=`host ${CLIENTNODE} | rev | cut -d ' ' -f1 | rev`
	STORAGE_PATH="$SERVICE_FOLDER/storage"
	STORAGE_METADATA_PATH="$SERVICE_FOLDER/metadata"
	APP_PATH="$SERVICE_FOLDER/app"
	APP_BIN_PATH="$APP_PATH/bin"
	MODEL_PATH="$SERVICE_FOLDER/model"
	MODEL_BIN_PATH="$MODEL_PATH/bin"
	STUBS_PATH="$APP_PATH/stubs"
	DEPLOY_PATH="$STORAGE_PATH/deploy_path/"
	DEPLOY_PATH_SRC="$DEPLOY_PATH/src"	
	DATACLAYCLIENTCONFIG="$SERVICE_FOLDER/cfgfiles/client.properties"
	DATACLAYGLOBALCONFIG="$SERVICE_FOLDER/cfgfiles/global.properties"
	DATACLAYSESSIONCONFIG="$SERVICE_FOLDER/cfgfiles/session.properties"

	# Host job config
	cat $GLOBAL_JOB_CONFIG > $SERVICE_CONFIG
	echo "######## $SERVICENAME environment variables ########" >> $SERVICE_CONFIG
	echo "export TRACING=$TRACING" >> $SERVICE_CONFIG
	echo "export SERVICE_FOLDER=$SERVICE_FOLDER" >> $SERVICE_CONFIG
	
	echo "export FLAGS=\"$FLAGS\"" >> $SERVICE_CONFIG
	echo "export SHUTDOWN_TIMEOUT=$SHUTDOWN_TIMEOUT" >> $SERVICE_CONFIG
	
	echo "export DATACLAYGLOBALCONFIG=$DATACLAYGLOBALCONFIG" >> $SERVICE_CONFIG
	echo "export DATACLAYCLIENTCONFIG=$DATACLAYCLIENTCONFIG" >> $SERVICE_CONFIG
	echo "export DATACLAYSESSIONCONFIG=$DATACLAYSESSIONCONFIG" >> $SERVICE_CONFIG
	echo "export APP_PATH=$APP_PATH" >> $SERVICE_CONFIG
	echo "export APP_BIN_PATH=$APP_BIN_PATH" >> $SERVICE_CONFIG
	echo "export MODEL_PATH=$MODEL_PATH" >> $SERVICE_CONFIG
	echo "export MODEL_BIN_PATH=$MODEL_BIN_PATH" >> $SERVICE_CONFIG
	echo "export STUBS_PATH=$STUBS_PATH" >> $SERVICE_CONFIG
	
	##### PATHS, PYTHONPATHS, ... 
	# PATH order: orchestration node path (for propagation), node path, dataclay path 
	# PYTHONPATH order: orchestration node pythonpath (for propagation), node pythonpath, dataclay pythonpath 
	# LD_LIBRARY_PATH order: same...
	
	echo "export PATH=$PATH:\$PATH" >> $SERVICE_CONFIG
    echo "export PYTHONPATH=$PYCLAY_PATH:$PYTHONPATH:\$PYTHONPATH:"  >> $SERVICE_CONFIG
    echo "export LD_LIBRARY_PATH=$DATACLAY_EXT_BIND:$LD_LIBRARY_PATH:\$LD_LIBRARY_PATH" >> $SERVICE_CONFIG
    echo "export CLASSPATH=$DATACLAY_JAR:$CLASSPATH:\$CLASSPATH" >> $SERVICE_CONFIG
	echo "export DATACLAY_JAR=$DATACLAY_JAR" >> $SERVICE_CONFIG
	echo "################" >> $SERVICE_CONFIG

	#  LM
    echo "export LOGICMODULE_PORT_TCP=$LOGICMODULE_PORT" >> $SERVICE_CONFIG
	echo "export DATACLAY_ADMIN_USER=admin" >> $SERVICE_CONFIG
	echo "export DATACLAY_ADMIN_PASSWORD=admin" >> $SERVICE_CONFIG
	# DSs	
	echo "export DEPLOY_PATH=$DEPLOY_PATH" >> $SERVICE_CONFIG
	echo "export DEPLOY_PATH_SRC=$DEPLOY_PATH_SRC" >> $SERVICE_CONFIG
	echo "export LOGICMODULE_HOST=$LOGICMODULE_IP" >> $SERVICE_CONFIG
	echo "export DATASERVICE_NAME=$DATACLAY_HOST" >> $SERVICE_CONFIG
	echo "export DATASERVICE_JAVA_PORT_TCP=$JAVA_PORT" >> $SERVICE_CONFIG
	echo "export DATASERVICE_PYTHON_PORT_TCP=$PYTHON_PORT" >> $SERVICE_CONFIG
	
	## Extrae
	echo "export EXTRAE_CONFIG_FILE=$EXTRAE_CONFIG_FILE" >> $SERVICE_CONFIG
	echo "export EXTRAE_SKIP_AUTO_LIBRARY_INITIALIZE=1"  >> $SERVICE_CONFIG
	echo "export PYCLAY_EXTRAE_WRAPPER_LIB=$PYCLAY_EXTRAE_WRAPPER_LIB" >> $SERVICE_CONFIG
	echo "export JAVACLAY_EXTRAE_WRAPPER_LIB=$JAVACLAY_EXTRAE_WRAPPER_LIB" >> $SERVICE_CONFIG

	
}

function create_script { 
	# FIXME: SERVICE_CONFIG is a pseudo-global unsafe variable
	SCRIPT_PATH=$1
	echo "#!/bin/bash" > $SCRIPT_PATH	
	echo "set -e" >> $SCRIPT_PATH
	cat $SERVICE_CONFIG >> $SCRIPT_PATH
	if [ ! -z "$PROLOG_SCRIPT" ]; then 
		cat $PROLOG_SCRIPT >> $SCRIPT_PATH
		printf "\n" >> $SCRIPT_PATH 
	fi
	if [ ! -z "$PROLOG_CMD" ]; then 
		echo $PROLOG_CMD >> $SCRIPT_PATH
	fi
}

function generate_global_properties { 
    echo "echo \"STORAGE_PATH=$STORAGE_PATH\" > $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
    echo "echo \"STORAGE_METADATA_PATH=$STORAGE_METADATA_PATH\" >> $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
    echo "echo \"STATE_FILE_PATH=$STORAGE_PATH/state.txt\" >> $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
    echo "echo \"EE_PERSISTENT_INFO_PATH=$STORAGE_PATH/\" >> $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
    echo "echo \"DEFAULT_GLOBALGC_CACHE_PATH=$STORAGE_PATH/\" >> $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
	if [ ! -z "$GLOBAL_PROPS" ] ; then
		while IFS= read -r line
		do
			dataclaywarn "Found global properties configuration: $line"
    		echo "echo \"$line\" >> $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
		done < "$GLOBAL_PROPS"
	fi
	if [ "$DEBUG" == True ]; then 
   		echo "echo \"CHECK_LOG4J_DEBUG=true\" >> $DATACLAYGLOBALCONFIG" >> $RUN_SCRIPT
	fi 
}

function generate_client_properties { 
    echo "echo \"HOST=$LOGICMODULE_IP\" > $DATACLAYCLIENTCONFIG" >> $RUN_SCRIPT
    echo "echo \"TCPPORT=$LOGICMODULE_PORT\" >> $DATACLAYCLIENTCONFIG" >> $RUN_SCRIPT
}

function generate_session_properties { 

    echo "echo \"DataClayClientConfig=$DATACLAYCLIENTCONFIG\" > $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    echo "echo \"Account=$DATACLAY_USR\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    echo "echo \"Password=$DATACLAY_PWD\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    echo "echo \"StubsClasspath=$STUBS_PATH\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    echo "echo \"DataSetForStore=$DATACLAY_DATASET\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    echo "echo \"DataSets=$DATACLAY_DATASET\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    echo "echo \"DataClayGlobalConfig=$DATACLAYGLOBALCONFIG\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
	if [ "$TRACING" = true ] ; then
    	echo "echo \"ExtraeStartingTaskID=$EXTRAE_STARTING_TASK_ID\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    	echo "echo \"Tracing=True\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    	echo "echo \"pyClayExtraeWrapperLib=$PYCLAY_EXTRAE_WRAPPER_LIB\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
    	echo "echo \"javaClayExtraeWrapperLib=$JAVACLAY_EXTRAE_WRAPPER_LIB\" >> $DATACLAYSESSIONCONFIG" >> $RUN_SCRIPT
	fi
}

# ===================== DEPLOYMENT SCRIPTS ======================================= #

function deploy { 
	start_deploy=$(date +%s.%3N)
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	
	# The caller should provide both the JAVA_PORT and PYTHON_PORT
	JAVA_PORT=$4
	PYTHON_PORT=$5
	# Both are required for Python dataservices (as the JAVA_PORT is the StorageLocation,
	# i.e. the Java backend to which Python will connect).
	# Java dataservices only require the JAVA_PORT
	
	dataclayecho "Deploying $SERVICENAME to $HOSTNAME... (parameters: JAVA_PORT=$JAVA_PORT, PYTHON_PORT=$PYTHON_PORT)"
	create_service_config $JAVA_PORT $PYTHON_PORT
	DEPLOY_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_deploy.XXXX)
	create_script $DEPLOY_SCRIPT 	
	
	####### DEPLOY SCRIPT ####### 
	# prepare paths
	echo "mkdir -p $SERVICE_FOLDER" >> $DEPLOY_SCRIPT
	echo "mkdir -p $SERVICE_FOLDER/cfgfiles" >> $DEPLOY_SCRIPT
	echo "mkdir -p $DEPLOY_PATH" >> $DEPLOY_SCRIPT
	echo "mkdir -p $DEPLOY_PATH_SRC" >> $DEPLOY_SCRIPT
	echo "mkdir -p $STORAGE_PATH" >> $DEPLOY_SCRIPT
	echo "mkdir -p $STORAGE_METADATA_PATH" >> $DEPLOY_SCRIPT
	
	chmod +x $DEPLOY_SCRIPT
	if [ $SHARED_FS == true ]; then
		bash $DEPLOY_SCRIPT
		cp $LOG4J_CONFIG $SERVICE_FOLDER/cfgfiles/log4j2.xml
		cp $DEPLOY_SCRIPT $SERVICE_FOLDER/deploy
		
	else
		# Deploy 
		ssh "${HOSTNAME}" "bash -s" < $DEPLOY_SCRIPT
		# Send log4j configuration
		scp -q $LOG4J_CONFIG $HOSTNAME:$SERVICE_FOLDER/cfgfiles/log4j2.xml
		# Send script
		scp -q $DEPLOY_SCRIPT $HOSTNAME:$SERVICE_FOLDER/deploy
	fi 
	
	# Clean temporary scripts
	rm $DEPLOY_SCRIPT
	
	end_deploy=$(date +%s.%3N)
	dataclayecho "${SERVICENAME} deployed to $HOSTNAME ($(echo "$end_deploy - $start_deploy" | bc -l) sec)"
}

function deploy_client { 
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	
	# Note that client deployment does not use/need neither JAVA_PORT nor PYTHON_PORT

	deploy $@ #common deploy
	
	create_service_config

	RUN_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_run.XXXX) # i.e. 24000_LM
	create_script $RUN_SCRIPT 
	
	# generate global properties 
	generate_global_properties
	
	if [ ! -f $DATACLAY_JOB_FOLDER/client.config ]; then 
		# in case client is named differently
		ln -s $SERVICE_CONFIG $DATACLAY_JOB_FOLDER/client.config
	fi
	echo "mkdir -p $APP_PATH" >> $RUN_SCRIPT
	echo "mkdir -p $APP_BIN_PATH" >> $RUN_SCRIPT
	echo "mkdir -p $STUBS_PATH" >> $RUN_SCRIPT
	echo "mkdir -p $MODEL_PATH" >> $RUN_SCRIPT
	echo "mkdir -p $MODEL_BIN_PATH" >> $RUN_SCRIPT
	# Generate client properties 
	generate_client_properties
	# Generate session.properties. If --tracing was provided, add session.properties field. 
	generate_session_properties
	
	# generate_env_file $SERVICENAME $RUN_SCRIPT
	
	echo "cd $APP_PATH"  >> $RUN_SCRIPT
	echo "$DATACLAY_BASE/scripts/dataclaycmd.sh \${@:2}" >> $RUN_SCRIPT

	chmod +x $RUN_SCRIPT
	if [ $SHARED_FS == true ]; then
		mkdir -p $SERVICE_FOLDER
		cp $RUN_SCRIPT $SERVICE_FOLDER/client
	else		
		# Send scripts
		echo "mkdir -p $SERVICE_FOLDER" | ssh "${HOSTNAME}" bash -s #sanity check
		scp -q $RUN_SCRIPT $HOSTNAME:$SERVICE_FOLDER/client
	fi 
	
	# Clean temporary scripts
	rm $RUN_SCRIPT		
}

function start { 
	start_start=$(date +%s.%3N)
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name
	
	# The caller should provide both the JAVA_PORT and PYTHON_PORT
	JAVA_PORT=$4
	PYTHON_PORT=$5
	# Both are required for Python dataservices (as the JAVA_PORT is the StorageLocation,
	# i.e. the Java backend to which Python will connect).
	# Java dataservices only require the JAVA_PORT

	dataclayecho "Starting $SERVICENAME to $HOSTNAME... (parameters: JAVA_PORT=$JAVA_PORT, PYTHON_PORT=$PYTHON_PORT)"
	create_service_config $JAVA_PORT $PYTHON_PORT

	RUN_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_run.XXXX) # i.e. 24000_LM
	create_script $RUN_SCRIPT 
	
	# generate global properties 
	generate_global_properties
	
	echo "cd $SERVICE_FOLDER" >> $RUN_SCRIPT
	echo "echo \"Starting ${SERVICENAME}\"" >> $RUN_SCRIPT
	echo "mkdir -p $SERVICE_FOLDER/logs/" >> $RUN_SCRIPT

	if [[ $SERVICENAME == dspython* ]]; then
		number=$(cut -d'_' -f 2 <<< $SERVICENAME)
        numa_idx=$(( ($number - 1) ))
		echo "Going to issue the following command: \`numactl -N ${numa_idx} -m ${numa_idx}\`"
		echo "nohup numactl -N ${numa_idx} -m ${numa_idx} -- python -m dataclay.executionenv.server --service >${LOG_DIR}/${SERVICENAME}.out 2> ${LOG_DIR}/${SERVICENAME}.err &" >> $RUN_SCRIPT
	elif [[ $SERVICENAME == dsjava* ]]; then
		ARGS=""
		ARGS="$ARGS -Dlog4j.configurationFile=$SERVICE_FOLDER/cfgfiles/log4j2.xml"
		ARGS="$ARGS -Dcom.google.inject.internal.cglib.\$experimental_asm7=true"
		ARGS="$ARGS -javaagent:/apps/DATACLAY/dependencies/aspectjweaver.jar"
		ARGS="$ARGS -Daj.weaving.verbose=false -Dorg.aspectj.weaver.showWeaveInfo=false"
		echo "export LD_PRELOAD=${EXTRAE_HOME}/lib/libpttrace.so" >> $RUN_SCRIPT
		echo "nohup java $ARGS -cp "$DATACLAY_JAR" es.bsc.dataclay.dataservice.server.DataServiceSrv >${LOG_DIR}/${SERVICENAME}.out 2> ${LOG_DIR}/${SERVICENAME}.err &" >> $RUN_SCRIPT
	else
		ARGS=""
		ARGS="$ARGS -Dlog4j.configurationFile=$SERVICE_FOLDER/cfgfiles/log4j2.xml"
		ARGS="$ARGS -Dcom.google.inject.internal.cglib.\$experimental_asm7=true"
		ARGS="$ARGS -javaagent:/apps/DATACLAY/dependencies/aspectjweaver.jar"
		ARGS="$ARGS -Daj.weaving.verbose=false -Dorg.aspectj.weaver.showWeaveInfo=false"
		echo "export LD_PRELOAD=${EXTRAE_HOME}/lib/libpttrace.so" >> $RUN_SCRIPT
		echo "nohup java $ARGS -cp "$DATACLAY_JAR" es.bsc.dataclay.logic.server.LogicModuleSrv >${LOG_DIR}/${SERVICENAME}.out 2> ${LOG_DIR}/${SERVICENAME}.err &" >> $RUN_SCRIPT
	fi	

		
	chmod +x $RUN_SCRIPT
	if [ $SHARED_FS == true ]; then
		mkdir -p $SERVICE_FOLDER
		cp $RUN_SCRIPT $SERVICE_FOLDER/start
	else		
		# Send scripts
		echo "mkdir -p $SERVICE_FOLDER" | ssh "${HOSTNAME}" bash -s #sanity check
		scp -q $RUN_SCRIPT $HOSTNAME:$SERVICE_FOLDER/start
	fi 
	
	# Run 
	echo "$SERVICE_FOLDER/start" | ssh "${HOSTNAME}" bash -s
		
	# Clean temporary scripts
	rm $RUN_SCRIPT
	end_start=$(date +%s.%3N)
	dataclayecho "${SERVICENAME} started in $HOSTNAME ($(echo "$end_start - $start_start" | bc -l) sec)"
}

# ===================== STOP SCRIPTS ======================================= #
function stop { 
	start_stop=$(date +%s.%3N)
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	
	create_service_config
	
	dataclayecho "Stopping ${SERVICENAME} at $HOSTNAME"
	STOP_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_stop.XXXX)
	create_script $STOP_SCRIPT
	
	SIGNAL="SIGTERM"
	if [[ $SERVICENAME == "dspython"* ]]; then 
		SIGNAL="SIGINT"
	fi 

	chmod +x $STOP_SCRIPT
	if [ $SHARED_FS == true ]; then
		mkdir -p $SERVICE_FOLDER
		cp $STOP_SCRIPT $SERVICE_FOLDER/stop
	else 
		# Send scripts
		echo "mkdir -p $SERVICE_FOLDER" | ssh "${HOSTNAME}" bash -s #sanity check
		scp -q $STOP_SCRIPT $HOSTNAME:$SERVICE_FOLDER/stop
	fi
	
	echo "$SERVICE_FOLDER/stop" | ssh "${HOSTNAME}" bash -s
	
	# Clean temporary scripts
	rm $STOP_SCRIPT
	end_stop=$(date +%s.%3N)
	dataclayecho "${SERVICENAME} stopped from $HOSTNAME ($(echo "$end_stop - $start_stop" | bc -l) sec)"
}

function clean { 
	start_clean=$(date +%s.%3N)
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	SERVICE_FOLDER="\$HOME/.dataClay/$DATACLAY_JOBID/${SERVICENAME}"
	
	if [ $SHARED_FS == true ]; then
		rm -rf $SERVICE_FOLDER
	else
		echo "rm -rf $SERVICE_FOLDER" | ssh "${HOSTNAME}" bash -s
	fi
	
	end_clean=$(date +%s.%3N)
	dataclayecho "${SERVICENAME} cleaned from $HOSTNAME ($(echo "$end_clean - $start_clean" | bc -l) sec)"
}

# ==================== SERVICES ============================ #

#=== FUNCTION ================================================================
# NAME: prepare_available_ports
# DESCRIPTION: Create an array of ports for each service depending on the 
# 				number of nodes. It may be not necessary.
# PARAMETER 1: ---
# OUTPUT: AVAILABLE_PORTS, JAVA_PORT, JAVA_PORT, LOGICMODULE_PORT
#=============================================================================
function prepare_available_ports {
	start_prepare_available_ports=$(date +%s.%3N)
	DSNODES=${HOSTS[@]:2}  # DS nodes
	NUM_HOSTS=0
	for node in ${HOSTS[@]}; do NUM_HOSTS=$(($NUM_HOSTS + 1)) ; done
	NUM_DSNODES=$(( $NUM_HOSTS - 2 )) #??? Wht -2 ??? !!! One for client, one for Logic Module.
	JAVA_SL_NUM=$(($JAVA_SL_PER_NODE * $NUM_DSNODES))

	# Set available ports
	if [ -z "$AVAILABLE_PORTS" ]; then
		AVAILABLE_PORTS=(1111)
		for j in $(seq 1 $JAVA_SL_NUM); do
			JAVA_PORT=$(( $JAVA_DS_BASE_PORT + j ))
			AVAILABLE_PORTS=(${AVAILABLE_PORTS[@]} $JAVA_PORT)
			for k in $(seq 1 $PYTHON_EE_PER_SL); do
				node_index=$(( ($j - 1) * $PYTHON_EE_PER_SL + $k ))
				PYTHON_PORT=$(( $PYTHON_DS_BASE_PORT + $node_index ))
				AVAILABLE_PORTS=(${AVAILABLE_PORTS[@]} $PYTHON_PORT)
			done
		done
	fi
	LOGICMODULE_PORT=${AVAILABLE_PORTS[0]}
	# Iterate the loop to read and print each array element
	printf "$PREFIX - using ports: "
	for value in "${AVAILABLE_PORTS[@]}"
	do
		printf "$value "
	done
	echo ""
	# check available ports size
	EXPECTED_PORTS=$((1 + $JAVA_SL_NUM + $PYTHON_EE_PER_SL * $JAVA_SL_NUM))
	NUM_PORTS=${#AVAILABLE_PORTS[@]}
	if [ "$NUM_PORTS" -ne "$EXPECTED_PORTS" ]; then
		dataclayerr "Available ports not sufficient. Expected $EXPECTED_PORTS ports but $NUM_PORTS were given: ${AVAILABLE_PORTS[@]}"
	fi
	
	end_prepare_available_ports=$(date +%s.%3N)
	dataclayecho "Prepared available ports ($(echo "$end_prepare_available_ports - $start_prepare_available_ports" | bc -l) sec)"
}

function dataclaydeploy { 
	start_dataclaydeploy=$(date +%s.%3N)

	dataclayclean #??? Why is removed in DevelAlex ???
	dataclaywarn "Job was not deployed. Going to deploy."
	dataclayinfo "========== Deploying dataClay =========="
	prepare_available_ports #??? Why is removed in DevelAlex ???

	dataclayecho "- deploying to hosts = \"$HOSTS\""
	HOSTS=($(echo $HOSTS | tr " " "\n"))
	if [ "${#HOSTS[@]}" -lt 3 ]; then
		dataclayerr "Minimum 3 hosts must be provided (logic module, a data service node and a client node)"
	fi
	CLIENTNODE=${HOSTS[0]} #1st node for client 
	LMNODE=${HOSTS[1]}     #2nd node for LM
	DSNODES=${HOSTS[@]:2}  # DS nodes

	create_globaljob_config

	#??? Should i Clean like Alex ???
	deploy $LMNODE ${LM_HOSTID} logicmodule
	i=1
	wait_pids=()
	current_available_port_idx=1
	for NODE in $DSNODES; do
		for j in $(seq 1 $JAVA_SL_PER_NODE); do
			SERVICENAME=dsjava${i}_${j}
			JAVA_PORT=${AVAILABLE_PORTS[current_available_port_idx]}
			current_available_port_idx=$((current_available_port_idx + 1))
			deploy $NODE ${DSNAME_PREFIX}${i} $SERVICENAME $JAVA_PORT &
			wait_pids+=($!)
			for k in $(seq 1 $PYTHON_EE_PER_SL); do
				PYTHON_PORT=${AVAILABLE_PORTS[current_available_port_idx]}
				current_available_port_idx=$((current_available_port_idx + 1))
				node_index=$(( ($j - 1) * $PYTHON_EE_PER_SL + $k ))
				SERVICENAME=dspython${i}_${node_index}
				deploy $NODE ${DSNAME_PREFIX}${i} $SERVICENAME $JAVA_PORT $PYTHON_PORT &
				wait_pids+=($!)
			done
		done 

		i=$(($i + 1))
	done

	for pid in ${wait_pids[*]}; do
		wait $pid
	done

	deploy_client $CLIENTNODE ${CLIENT_HOSTID} client client:$DATACLAY_VERSION

	echo "$DATACLAY_JOBID" >> $DEPLOYED_DATACLAY_JOBS
	end_dataclaydeploy=$(date +%s.%3N)
	dataclayinfo "========== dataClay deployed! ========== ($(echo "$end_dataclaydeploy - $start_dataclaydeploy" | bc -l) sec)"
}

function dataclaystart { 
	start_dataclaystart=$(date +%s.%3N)

	if [ "$DEPLOYED" == false ]; then 
		dataclaydeploy
	else 
		dataclayinfo "INFO: Already deployed dataClay found."
	fi

	dataclayinfo "========== Starting dataClay ========== "
	prepare_available_ports
	# Get client config to get DS nodes and LM node
	source $GLOBAL_JOB_CONFIG
	start $LMNODE ${LM_HOSTID} logicmodule
	i=1
	wait_pids=()
	current_available_port_idx=1
	for NODE in $DSNODES; do
		for j in $(seq 1 $JAVA_SL_PER_NODE); do
			SERVICENAME=dsjava${i}_${j}
			JAVA_PORT=${AVAILABLE_PORTS[current_available_port_idx]}
			current_available_port_idx=$((current_available_port_idx + 1))
			start $NODE ${DSNAME_PREFIX}${i} $SERVICENAME $JAVA_PORT &
			wait_pids+=($!)
			for k in $(seq 1 $PYTHON_EE_PER_SL); do
				PYTHON_PORT=${AVAILABLE_PORTS[current_available_port_idx]}
				current_available_port_idx=$((current_available_port_idx + 1))
				node_index=$(( ($j - 1) * $PYTHON_EE_PER_SL + $k ))
				SERVICENAME=dspython${i}_${node_index}
				start $NODE ${DSNAME_PREFIX}${i} $SERVICENAME $JAVA_PORT $PYTHON_PORT &
				wait_pids+=($!)
			done
		done

		i=$(($i + 1))
	done

	for pid in ${wait_pids[*]}; do
		wait $pid
	done
	
	############ VERIFY ############ 
	# Wait for dataClay to be read
	$SCRIPTDIR/dataclay WaitForDataClayToBeAlive 20 3
	
	# Wait for backends 
	for DSNODE in $DSNODES; do
		DSCOUNTER=0
		dataclayecho "Waiting for $DSNODE Java execution environments to be ready... "
	   
		while [ $DSCOUNTER -lt $JAVA_SL_PER_NODE ]; do
	    	$SCRIPTDIR/dataclay GetBackends admin admin java
	    	DSCOUNTER=`$SCRIPTDIR/dataclay GetBackends admin admin java | grep "${DSNAME_PREFIX}" | wc -l`
			sleep 5
		done
		dataclayecho "$DSNODE Java execution environments are ready"
	
		DSCOUNTER=0
		dataclayecho "Waiting for $DSNODE Python execution environments to be ready... "
		TOTAL_PYTHON_PER_NODE=$(( $PYTHON_EE_PER_SL * $JAVA_SL_PER_NODE ))
		while [ $DSCOUNTER -lt $TOTAL_PYTHON_PER_NODE ]; do
	   		dataclayecho "`$SCRIPTDIR/dataclay GetBackends admin admin python`"
			DSCOUNTER=`$SCRIPTDIR/dataclay GetBackends admin admin python | grep "${DSNAME_PREFIX}" | wc -l`
		done
		dataclayecho "$DSNODE Python execution environments are ready"
	done
	
	end_dataclaystart=$(date +%s.%3N)
	dataclayinfo "========== dataClay started! ========== ($(echo "$end_dataclaystart - $start_dataclaystart" | bc -l) sec)"
}

function dataclaystop { 
	start_dataclaystop=$(date +%s.%3N)
	dataclayinfo "========== Stopping dataClay ========== "

	# ------------------------------ dataClay Job configuration -------------------------------------------
	# Get client config to get DS nodes and LM node
	GLOBAL_JOB_CONFIG="$HOME/.dataClay/$DATACLAY_JOBID/job.config"
	source $GLOBAL_JOB_CONFIG
	#------------------------------------------------------------------------------------------------------
	i=1
	wait_pids=()
	for NODE in $DSNODES; do
		#### NOTE: stop first dspython
		for j in $(seq 1 $JAVA_SL_PER_NODE); do
			SERVICENAME=dsjava${i}_${j}
			stop $NODE ${DSNAME_PREFIX}${i} $SERVICENAME &
			wait_pids+=($!)
			for k in $(seq 1 $PYTHON_EE_PER_SL); do
				node_index=$(( ($j - 1) * $PYTHON_EE_PER_SL + $k ))
				SERVICENAME=dspython${i}_${node_index}
				stop $NODE ${DSNAME_PREFIX}${i} $SERVICENAME &
				wait_pids+=($!)
			done
		done 
		i=$(($i + 1))
	done

	for pid in ${wait_pids[*]}; do
		wait $pid
	done

	stop $LMNODE ${LM_HOSTID} logicmodule
	end_dataclaystop=$(date +%s.%3N)
	dataclayinfo "========== dataClay stopped! ========== ($(echo "$end_dataclaystop - $start_dataclaystop" | bc -l) sec)"
}


function dataclayclean { 
	start_dataclayclean=$(date +%s.%3N)
	dataclayinfo "========== Cleaning dataClay ========== "

	# remove from deployed.jobs
	sed -i "/${DATACLAY_JOBID}$/d" $DEPLOYED_DATACLAY_JOBS
	# replace from job pids 
	sed -i "/${DATACLAY_JOBID}$/d" $DATACLAY_JOB_PIDS
	echo "$PPID=$DATACLAY_JOBID" >> $DATACLAY_JOB_PIDS
		
	if [ -d $DATACLAY_JOB_FOLDER ]; then
		CLEAN=true
		dataclaystop
		i=1
		wait_pids=()
		for NODE in $DSNODES; do
			for j in $(seq 1 $JAVA_SL_PER_NODE); do
				SERVICENAME=dsjava${i}_${j}
				clean $NODE ${DSNAME_PREFIX}${i} $SERVICENAME &
				wait_pids+=($!)
				for k in $(seq 1 $PYTHON_EE_PER_SL); do
					node_index=$(( ($j - 1) * $PYTHON_EE_PER_SL + $k ))
					SERVICENAME=dspython${i}_${node_index}
					clean $NODE ${DSNAME_PREFIX}${i} $SERVICENAME &
					wait_pids+=($!)
				done
			done 
			i=$(($i + 1))
		done

		for pid in ${wait_pids[*]}; do
			wait $pid
		done

		clean $LMNODE ${LM_HOSTID} logicmodule
		clean $CLIENTNODE ${CLIENT_HOSTID} client
		rm -rf $DATACLAY_JOB_FOLDER
	fi
	
	end_dataclayclean=$(date +%s.%3N)
	dataclayinfo "========== dataClay cleaned! ========== ($(echo "$end_dataclayclean - $start_dataclayclean" | bc -l) sec)"
	
}

# ==================== MAIN ============================ #

if [ "$#" -lt 1 ]; then
	dataclayerr "Please provide argument to start or stop dataClay" 
fi
START=false
STOP=false
RESTART=false
if [ "$1" == "start" ]; then 
	START=true 
elif [ "$1" == "stop" ]; then 
	STOP=true
elif [ "$1" == "restart" ]; then 
	RESTART=true 
else
	dataclayerr "First argument must be start or stop"
fi 
# Check DATACLAY_BASE is set 
SCRIPTDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
DATACLAY_BASE=$SCRIPTDIR/..
#if [ -z $DATACLAY_BASE ]; then
#        dataclayerr "Please set DATACLAY_BASE in your host (via bashrc, ...)!"
#fi 
if [ ! -d $HOME/.dataClay ]; then
	dataclaywarn "Creating $HOME/.dataClay folder." 
	mkdir $HOME/.dataClay 
fi
DATACLAY_VERSION=$(cat $DATACLAY_BASE/VERSION.txt)
DATACLAY_JOB_PIDS=$HOME/.dataClay/job.pids
DEPLOYED_DATACLAY_JOBS=$HOME/.dataClay/deployed.jobs

### PREPARE ###
if [ ! -f $DATACLAY_JOB_PIDS ]; then touch $DATACLAY_JOB_PIDS; fi
if [ ! -f $DEPLOYED_DATACLAY_JOBS ]; then touch $DEPLOYED_DATACLAY_JOBS; fi

if [ ! -z $SLURM_JOBID ]; then 
	export DATACLAY_JOBID=$SLURM_JOBID
    dataclaywarn "SLURM JOB ID detected. Using it. DATACLAY_JOBID = $DATACLAY_JOBID"
fi

if [ -z $DATACLAY_JOBID ]; then
	ID=$($SCRIPTDIR/dataclayid $PPID)
	# if ID exists, set it 
	if [ ! -z $ID ]; then
		export DATACLAY_JOBID=$ID
    	dataclaywarn "Found current process $PPID using DATACLAY_JOBID"
	fi
fi 

# Check DATACLAY_JOBID is set 
if [ -z $DATACLAY_JOBID ]; then
	if [[ $(ls -l $HOME/.dataClay | grep "^d") ]]; then 
		LAST_JOB=$(basename $(ls -td -- $HOME/.dataClay/*/ | head -n 1))
	fi
	if [ -z "$LAST_JOB" ]; then
		NUMERIC_VERSION=${DATACLAY_VERSION%.dev}
		export DATACLAY_JOBID=$((${NUMERIC_VERSION//.} * 1000))
	else 
		export DATACLAY_JOBID=$(($LAST_JOB + 1))
	fi
    dataclaywarn "DATACLAY_JOBID environment not set. Generating one = $DATACLAY_JOBID"
else 
    dataclayinfo "Found DATACLAY_JOBID = $DATACLAY_JOBID"
fi

if [ -z $ID ]; then 
	# add parent pid to job pids of dataClay 
	echo "$PPID=$DATACLAY_JOBID" >> $DATACLAY_JOB_PIDS
fi
if [ -z $DATACLAY_JOBID ]; then
        dataclayerr "CRITICAL: please set DATACLAY_JOBID!"
fi
DEPLOYED=false
while IFS= read -r line; do
  if [ "$line" == "$DATACLAY_JOBID" ]; then
  		DEPLOYED=true
  fi
done < "$DEPLOYED_DATACLAY_JOBS"

##### process arguments #####
shift

# global vars
mkdir -p $HOME/.dataClay/
DATACLAY_JOB_FOLDER="$HOME/.dataClay/$DATACLAY_JOBID"
LOG_DIR=${DATACLAY_JOB_FOLDER}/logs
GLOBAL_JOB_CONFIG=$DATACLAY_JOB_FOLDER/job.config
CLIENT_HOSTID="client"
LM_HOSTID="logicmodule"
DSNAME_PREFIX="dataservice"
DATACLAY_USR=bsc_user
DATACLAY_PWD=bsc_user
DATACLAY_DATASET=bsc_dataset
DATACLAY_JAVA_VERSION=8
DATACLAY_PYTHON_VERSION=3.7
SHARED_FS=FALSE
EXTRAE_STARTING_TASK_ID=0
JAVA_SL_PER_NODE=1
PYTHON_EE_PER_SL=1
JAVA_DS_BASE_PORT=2222
PYTHON_DS_BASE_PORT=2666
LOG4J_CONFIG=$DATACLAY_BASE/logging/info.xml
DEBUG=False
HOSTS="localhost localhost localhost" 

# Extrae 
PYCLAY_EXTRAE_WRAPPER_LIB=$DATACLAY_BASE/extrae/pyextrae/pyclay_extrae_wrapper.so
JAVACLAY_EXTRAE_WRAPPER_LIB=$DATACLAY_BASE/extrae/javaextrae/javaclay_extrae_wrapper.so
EXTRAE_CONFIG_FILE=$DATACLAY_BASE/extrae/extrae_basic.xml
###############################################################

# Start args
TRACING=false
FLAGS=""
GLOBAL_PROPS=""

# Stop args
SHUTDOWN_TIMEOUT=300

# Args
while test $# -gt 0
do
	case "$1" in
			--javaclay-path) 
				shift
				DATACLAY_JAR=$1
				dataclayecho "- using dataclay jar located at $DATACLAY_JAR"
		    	;;
		    --pyclay-path) 
				shift
				PYCLAY_PATH=$1
				dataclayecho "- using pyclay path $PYCLAY_PATH"
		    	;;
		    --available-ports) #??? Should i delete it ???
				shift
				AVAILABLE_PORTS=$1
				AVAILABLE_PORTS=($(echo $AVAILABLE_PORTS | tr " " "\n"))
				dataclayecho "- provided available ports $1"
				;;
			--python-ee-per-sl) 
		    	shift 
		    	PYTHON_EE_PER_SL=$1
	            dataclayecho "- setting python execution environment per storage location = $PYTHON_EE_PER_SL"
		    	;;
		    --pyclay-extrae-wrapper) 
		    	shift
		    	PYCLAY_EXTRAE_WRAPPER_LIB=$1
		    	dataclayecho "- using extrae wrapper = $PYCLAY_EXTRAE_WRAPPER_LIB"
		    	;;
		    --javaclay-extrae-wrapper) 
		    	shift
		    	JAVACLAY_EXTRAE_WRAPPER_LIB=$1
		    	dataclayecho "- using extrae wrapper = $JAVACLAY_EXTRAE_WRAPPER_LIB"
		    	;;
		    --extrae-starting-task-id)
		     	shift
		    	EXTRAE_STARTING_TASK_ID=$1
		    	dataclayecho "- using extrae starting task id = $EXTRAE_STARTING_TASK_ID"
		    	;;
		    --extrae-config-file) 
		    	shift 
		    	EXTRAE_CONFIG_FILE=$1 
		    	dataclayecho "- using extrae configuration file at $EXTRAE_CONFIG_FILE" 
		    	;;
		    --sharedfs) 
		    	SHARED_FS=true
		    	;;
			--hosts)
		   		shift
		    	HOSTS=$1
	            ;;
	        --prolog-cmd) 
	        	shift
	        	PROLOG_CMD=$1
	            dataclayecho "- setting prolog command = $PROLOG_CMD"
	        	;;
	        --prolog-script) 
	        	shift
	        	PROLOG_SCRIPT=$1
	            dataclayecho "- setting prolog script = $PROLOG_SCRIPT"
	        	;;
	        --globalprops) 
	        	shift 
	        	GLOBAL_PROPS=$1 
	            dataclayecho "- deploying global properties at $GLOBAL_PROPS"
	        	;;
	        --cleandeploy) 
	        	DEPLOYED=false
	            dataclaywarn "Clean deploy option provided."
	        	;;
	        --debug) 
	            FLAGS="$FLAGS $1"
	            LOG4J_CONFIG=$DATACLAY_BASE/logging/debug.xml
	            DEBUG=True
	            dataclayecho "- debug mode: enabled "
	            ;; 
	        --tracing)
		    	TRACING=true
	            FLAGS="$FLAGS $1" 
	            dataclayecho "- tracing mode: enabled "
	            ;;
			--shutdown-timeout)
		    	shift
		    	SHUTDOWN_TIMEOUT=$1
		    	dataclayecho "- shutdown timeout = $SHUTDOWN_TIMEOUT"
	            ;;
			--*) 
				dataclayerr "Wrong option $1 provided" 
				;;
			*)  
				dataclayerr "Wrong argument $1 provided"
            ;;
    esac
    shift
done

# ??? Que es esto ??? Parece que PROLOG_SCRIPT solo tiene un espacio..
if [ ! -f $PROLOG_SCRIPT ]; then 
	dataclayerr "Prolog $PROLOG_SCRIPT not found."
fi

if [ "$START" == true ]; then 
	dataclaystart
elif  [ "$STOP" == true ]; then 
	dataclaystop 
elif  [ "$RESTART" == true ]; then 
	dataclaystop
	dataclaystart
fi 
